{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import word2vecUtilities as wvu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Twitter Data as a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets read:  239082\n",
      "Elapsed time (seconds):  36.4074320793\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "datapath = '/Users/jorgecastanon/Documents/github/w2v/data/tweets.gz'\n",
    "tweets = sqlContext.read.json(datapath)\n",
    "tweets.registerTempTable(\"tweets\")\n",
    "twr = tweets.count()\n",
    "print \"Number of tweets read: \", twr \n",
    "# this line add ~7 seconds (from ~24.5 seconds to ~31.5 seconds)\n",
    "# Number of tweets read:  239082\n",
    "print \"Elapsed time (seconds): \", time.time() - t0\n",
    "#Elapsed time (seconds):  31.9646401405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Keywords: christmas, santa, turkey, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filterPath = '/Users/jorgecastanon/Documents/github/w2v/data/filter.txt'\n",
    "filter = pd.read_csv(filterPath,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Spark SQL to Filter Tweets:\n",
    "### + In english\n",
    "### + And containing at least one of the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets after filtering:  15999\n",
      "Elapsed time (seconds):  10.8425040245\n",
      "Percetage of Tweets Used:  0.0669184631214\n"
     ]
    }
   ],
   "source": [
    "# Construct SQL Command\n",
    "t0 = time.time()\n",
    "sqlString = \"(\"\n",
    "for substr in filter[0]: #iteration on the list of words to filter (at most 50-100 words)\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr+\"%' OR \"\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr.upper()+\"%' OR \"\n",
    "sqlString=sqlString[:-4]+\")\"\n",
    "sqlFilterCommand = \"SELECT lang, text FROM tweets WHERE (lang = 'en') AND \"+sqlString\n",
    "\n",
    "# Query tweets in english that contain at least one of the keywords\n",
    "tweetsDF = sqlContext.sql(sqlFilterCommand).cache()\n",
    "twf = tweetsDF.count()\n",
    "print \"Number of tweets after filtering: \", twf \n",
    "# last line add ~9 seconds (from ~0.72 seconds to ~9.42 seconds)\n",
    "print \"Elapsed time (seconds): \", time.time() - t0\n",
    "\n",
    "print \"Percetage of Tweets Used: \", float(twf)/twr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Tweets and Remove Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetsRDD = tweetsDF.select('text').rdd\n",
    "\n",
    "def parseAndRemoveStopWords(text):\n",
    "    t = text[0].replace(\";\",\" \").replace(\":\",\" \").replace('\"',' ').replace('-',' ')\n",
    "    t = t.replace(',',' ').replace('.',' ')\n",
    "    t = t.lower().split(\" \")\n",
    "    stop = stopwords.words('english')\n",
    "    return [i for i in t if i not in stop]\n",
    "\n",
    "tw = tweetsRDD.map(parseAndRemoveStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: returns a dataframe with words and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (seconds) to train Word2Vec:  6.75390815735\n"
     ]
    }
   ],
   "source": [
    "# map to df\n",
    "twDF = tw.map(lambda p: Row(text=p)).toDF()\n",
    "\n",
    "# default minCount = 5 (we may need to try something larger: 20-100 to reduce cost)\n",
    "# default vectorSize = 100 (we may want to keep default)\n",
    "t0 = time.time()\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=50, inputCol=\"text\", outputCol=\"result\")\n",
    "modelW2V = word2Vec.fit(twDF)\n",
    "wordVectorsDF = modelW2V.getVectors()\n",
    "print \"Elapsed time (seconds) to train Word2Vec: \", time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  404\n"
     ]
    }
   ],
   "source": [
    "vocabSize = wordVectorsDF.count()\n",
    "print \"Vocabulary Size: \", vocabSize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find top N closest words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eve</td>\n",
       "      <td>1.064899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xmas</td>\n",
       "      <td>0.952352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>0.913216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merry</td>\n",
       "      <td>0.787611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh</td>\n",
       "      <td>0.783243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ðŸŽ…</td>\n",
       "      <td>0.731680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ðŸŽ„</td>\n",
       "      <td>0.719252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  similarity\n",
       "0       eve    1.064899\n",
       "1      xmas    0.952352\n",
       "2  tomorrow    0.913216\n",
       "3     merry    0.787611\n",
       "4        oh    0.783243\n",
       "5        ðŸŽ…    0.731680\n",
       "6        ðŸŽ„    0.719252"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topN = 7\n",
    "synonymsDF = modelW2V.findSynonyms('christmas', topN).toPandas()\n",
    "synonymsDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As Expected, Unrelated terms are Inaccurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>share</td>\n",
       "      <td>0.740662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.692323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.691651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>part</td>\n",
       "      <td>0.691494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.677431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  similarity\n",
       "0   share    0.740662\n",
       "1       6    0.692323\n",
       "2  thanks    0.691651\n",
       "3    part    0.691494\n",
       "4       7    0.677431"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymsDF = modelW2V.findSynonyms('music', 5).toPandas()\n",
    "synonymsDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on top of Word2Vec using DF (spark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters (K) Used:  14\n",
      "Elapsed time (seconds) : 0.380414009094\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "\n",
    "K = int(math.floor(math.sqrt(float(vocabSize)/2)))\n",
    "         # K ~ sqrt(n/2) this is a rule of thumb for choosing K,\n",
    "         # where n is the number of words in the model\n",
    "         # feel free to choose K with a fancier algorithm\n",
    "         \n",
    "dfW2V = wordVectorsDF.select('vector').withColumnRenamed('vector','features')\n",
    "kmeans = KMeans(k=K, seed=1)\n",
    "modelK = kmeans.fit(dfW2V)\n",
    "labelsDF = modelK.transform(dfW2V).select('prediction').withColumnRenamed('prediction','labels')\n",
    "\n",
    "print \"Number of Clusters (K) Used: \", K\n",
    "print \"Elapsed time (seconds) :\", time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on Top of Word2Vec using DF (spark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxWordsVis = 5 # number of words to visualize\n",
    "\n",
    "numComponents = 3\n",
    "pca = PCA(k = numComponents, inputCol = 'features', outputCol = 'pcaFeatures')\n",
    "model = pca.fit(dfW2V)\n",
    "dfComp = model.transform(dfW2V).select(\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = 'christmas'\n",
    "nwords=200\n",
    "\n",
    "#############\n",
    "\n",
    "r = wvu.topNwordsToPlot(dfComp,wordVectorsDF,word,nwords)\n",
    "\n",
    "############\n",
    "fs=20 #fontsize\n",
    "w = r['word']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "height = 10\n",
    "width = 10\n",
    "fig.set_size_inches(width, height)\n",
    "\n",
    "ax.scatter(r['X'], r['Y'], r['Z'], color='red', s=100, marker='o', edgecolors='black')\n",
    "for i, txt in enumerate(w):\n",
    "    if(i<topN):\n",
    "        ax.text(r['X'].ix[i],r['Y'].ix[i],r['Z'].ix[i], '%s' % (txt), size=20, zorder=1, color='k')\n",
    "ax.set_xlabel('1st. Component', fontsize=fs)\n",
    "ax.set_ylabel('2nd. Component', fontsize=fs)\n",
    "ax.set_zlabel('3rd. Component', fontsize=fs)\n",
    "ax.set_title('Visualization of Word2Vec via PCA', fontsize=fs)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
