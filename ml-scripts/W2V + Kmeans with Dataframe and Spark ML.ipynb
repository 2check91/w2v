{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Twitter Data as a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (seconds):  29.2087728977\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "datapath = '/Users/jorgecastanon/Documents/github/w2v/data/tweets.gz'\n",
    "tweets = sqlContext.read.json(datapath)\n",
    "tweets.registerTempTable(\"tweets\")\n",
    "#print \"Number of tweets read: \", tweets.count() # this line add ~7 seconds (from ~24.5 seconds to ~31.5 seconds)\n",
    "print \"Elapsed time (seconds): \", time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Words to Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filterPath = '/Users/jorgecastanon/Documents/github/w2v/data/filter.txt'\n",
    "filter = pd.read_csv(filterPath,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Spark SQL to Filter Tweets:\n",
    "### + In english\n",
    "### + And containing at least one of the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (seconds):  1.01377296448\n"
     ]
    }
   ],
   "source": [
    "# Construct SQL Command\n",
    "t0 = time.time()\n",
    "sqlString = \"(\"\n",
    "for substr in filter[0]: #iteration on the list of words to filter (at most 50-100 words)\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr+\"%' OR \"\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr.upper()+\"%' OR \"\n",
    "sqlString=sqlString[:-4]+\")\"\n",
    "sqlFilterCommand = \"SELECT lang, text FROM tweets WHERE (lang = 'en') AND \"+sqlString\n",
    "\n",
    "# Query tweets in english that contain at least one of the keywords\n",
    "tweetsDF = sqlContext.sql(sqlFilterCommand)\n",
    "#print type(tweetsDF), tweetsDF.count() # this line add ~9 seconds (from ~0.72 seconds to ~9.42 seconds)\n",
    "print \"Elapsed time (seconds): \", time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and Remove Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetsRDD = tweetsDF.select('text').rdd\n",
    "\n",
    "def parseAndRemoveStopWords(text):\n",
    "    t = text[0].replace(\";\",\" \").replace(\":\",\" \").replace('\"',' ').replace('-',' ')\n",
    "    t = t.replace(',',' ').replace('.',' ')\n",
    "    t = t.lower().split(\" \")\n",
    "    stop = stopwords.words('english')\n",
    "    return [i for i in t if i not in stop]\n",
    "\n",
    "tw = tweetsRDD.map(parseAndRemoveStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: returns a dataframe with words and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time(seconds) : 22.9976389408\n"
     ]
    }
   ],
   "source": [
    "# map to df\n",
    "twDF = tw.map(lambda p: Row(text=p)).toDF()\n",
    "\n",
    "# default minCount = 5 (we may need to try something larger: 20-100 to reduce cost)\n",
    "# default vectorSize = 100 (we may want to keep default)\n",
    "t0 = time.time()\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=25, stepSize=0.1, inputCol=\"text\", outputCol=\"result\")\n",
    "modelW2V = word2Vec.fit(twDF)\n",
    "wordVectorsDF = modelW2V.getVectors()\n",
    "print \"Elapsed time(seconds) :\", time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  811\n"
     ]
    }
   ],
   "source": [
    "print \"Vocabulary Size: \", wordVectorsDF.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To feed force graph: findSynonyms used to find top N closest words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|          word|        similarity|\n",
      "+--------------+------------------+\n",
      "|           eve|0.8034414351704501|\n",
      "|          you!|0.7697983397627831|\n",
      "|    #christmas| 0.754777686709501|\n",
      "|          hope|0.7069539180475077|\n",
      "|       present|0.6931874739179668|\n",
      "|      midnight|0.6822633433563502|\n",
      "|            üéÅ|0.6784892791326919|\n",
      "|          babe|0.6613937562729849|\n",
      "|@niallofficial|0.6544346950755877|\n",
      "|          send|0.6445908439723395|\n",
      "|            üéÑ|0.6360973777773882|\n",
      "|          card|0.6330151491688999|\n",
      "|         louis|0.6310315485515334|\n",
      "|         would|0.6053057866691136|\n",
      "|             e|0.5979345863213892|\n",
      "|      presents|0.5733158987239777|\n",
      "|            üéÖ|0.5598128859776278|\n",
      "|          safe|0.5548107728343319|\n",
      "|          wish|0.5500323573645335|\n",
      "|          sony| 0.549303664868333|\n",
      "+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synonymsDF = modelW2V.findSynonyms(\"christmas\", 20)\n",
    "synonymsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on top of Word2Vec using DF (spark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time(seconds) : 1.18997311592\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "vocabSize=wordVectorsDF.count()\n",
    "K = int(math.floor(math.sqrt(float(vocabSize)/2)))\n",
    "         # K ~ sqrt(n/2) this is a rule of thumb for choosing K,\n",
    "         # where n is the number of words in the model\n",
    "         # feel free to choose K with a fancier algorithm\n",
    "           \n",
    "dfW2V = wordVectorsDF.select('vector').withColumnRenamed('vector','features')\n",
    "kmeans = KMeans(k=K, seed=1)\n",
    "modelK = kmeans.fit(dfW2V)\n",
    "labelsDF = modelK.transform(dfW2V).select('prediction').withColumnRenamed('prediction','labels')\n",
    "print \"Elapsed time(seconds) :\", time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toNumpy(df,colName):\n",
    "    '''\n",
    "    In .- spark dataframe with an specific column selected\n",
    "    Out .- numpy array of that column\n",
    "    '''\n",
    "    dfCol = df.select(colName)\n",
    "    return dfCol.map(lambda e: e[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vMatrix = toNumpy(wordVectorsDF,'vector')\n",
    "np.save('w2vMatrix.npy',w2vMatrix)\n",
    "\n",
    "words = toNumpy(wordVectorsDF,'word')\n",
    "np.save('words.npy',words)\n",
    "\n",
    "lables = toNumpy(labelsDF,'labels')\n",
    "np.save('labels.npy',words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
